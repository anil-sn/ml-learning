---

### **Project 30: Virtual Network Function (VNF) Performance Prediction**

**Objective:** To build a regression model that can predict the maximum achievable throughput (in Gbps) of a VNF based on its type, allocated resources (vCPUs, RAM), and workload characteristics (e.g., number of firewall rules).

**Dataset Source:** **Synthetically Generated**. We will create a realistic dataset that simulates VNF performance testing. The data will reflect logical relationships: more resources lead to better performance, but more complex configurations (like many firewall rules) degrade it.

**Model:** We will use the **XGBoost Regressor**. It is a state-of-the-art model for tabular data, perfectly suited for capturing the complex, non-linear relationships between resource allocation, configuration, and VNF performance.

**Instructions:**
This notebook is fully self-contained and does not require any external files or APIs. Simply run the entire code block in Google Colab.

**Implementation in Google Colab:**
```python
#
# ==================================================================================
#  Project 30: Virtual Network Function (VNF) Performance Prediction
# ==================================================================================
#
# Objective:
# This notebook builds a regression model to predict the performance (throughput)
# of a VNF based on its configuration and allocated resources, using a synthetic dataset.
#
# To Run in Google Colab:
# Copy and paste this entire code block into a single cell and run it.
#

# ----------------------------------------
# 1. Import Necessary Libraries
# ----------------------------------------
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# ----------------------------------------
# 2. Synthetic VNF Performance Data Generation
# ----------------------------------------
print("--- Generating Synthetic VNF Performance Dataset ---")

num_samples = 3000
data = []
vnf_types = ['Firewall', 'Router', 'LoadBalancer', 'IDS']

for _ in range(num_samples):
    vnf_type = random.choice(vnf_types)
    vcpus = random.randint(2, 16)
    ram_gb = random.choice([4, 8, 16, 32])
    
    # Configuration complexity affects performance
    if vnf_type == 'Firewall':
        config_complexity = np.random.randint(100, 5000) # Number of rules
    elif vnf_type == 'IDS':
        config_complexity = np.random.randint(500, 10000) # Number of signatures
    else:
        config_complexity = np.random.randint(10, 100) # e.g., number of routes/VIPs

    # --- Performance Formula ---
    # Base performance is driven by vCPUs (primary factor) and RAM (secondary)
    base_throughput = (vcpus * 1.5) + (ram_gb * 0.2)
    
    # Complexity introduces a performance penalty (non-linear)
    complexity_penalty = np.log1p(config_complexity) * 0.5
    if vnf_type in ['Firewall', 'IDS']:
        complexity_penalty *= 1.5 # These are more sensitive to complexity
    
    # Add random noise
    random_noise = np.random.normal(0, 0.5)
    
    # Calculate final throughput
    throughput_gbps = base_throughput - complexity_penalty + random_noise
    throughput_gbps = max(1, throughput_gbps) # Ensure a minimum performance
    
    data.append([vnf_type, vcpus, ram_gb, config_complexity, throughput_gbps])

df = pd.DataFrame(data, columns=['vnf_type', 'vcpus', 'ram_gb', 'config_complexity', 'throughput_gbps'])
print(f"Dataset generation complete. Created {len(df)} samples.")
print("\nDataset Sample:")
print(df.sample(5))


# ----------------------------------------
# 3. Data Splitting and Encoding
# ----------------------------------------
print("\n--- Splitting and Encoding Data ---")

X = df.drop(columns=['throughput_gbps'])
y = df['throughput_gbps']

# One-hot encode the 'vnf_type' categorical feature
X_encoded = pd.get_dummies(X, columns=['vnf_type'], drop_first=True)

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)
print(f"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}")


# ----------------------------------------
# 4. Model Training with XGBoost Regressor
# ----------------------------------------
print("\n--- Model Training ---")

model = xgb.XGBRegressor(
    objective='reg:squarederror',
    n_estimators=150,
    learning_rate=0.05,
    max_depth=6,
    random_state=42,
    n_jobs=-1
)

print("Training the XGBoost Regressor model...")
model.fit(X_train, y_train)
print("Training complete.")


# ----------------------------------------
# 5. Model Evaluation
# ----------------------------------------
print("\n--- Model Evaluation ---")
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f} Gbps")
print(f"  (On average, the model's throughput prediction is off by +/- {mae:.2f} Gbps)")
print(f"R-squared (RÂ²): {r2:.2%}")
print(f"  ({r2:.0%} of the variance in throughput can be explained by our features)")

# --- Visualization: Actual vs. Predicted ---
plt.figure(figsize=(8, 8))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Perfect Prediction')
plt.xlabel('Actual Throughput (Gbps)')
plt.ylabel('Predicted Throughput (Gbps)')
plt.title('Actual vs. Predicted VNF Throughput')
plt.legend()
plt.grid(True)
plt.show()


# ----------------------------------------
# 6. Feature Importance
# ----------------------------------------
print("\n--- Feature Importance: What drives VNF performance? ---")
fig, ax = plt.subplots(figsize=(10, 6))
xgb.plot_importance(model, ax=ax, height=0.8)
plt.title('Feature Importance in Predicting VNF Throughput')
plt.show()


# ----------------------------------------
# 7. Conclusion
# ----------------------------------------
print("\n--- Conclusion ---")
print(f"The XGBoost model successfully learned the complex relationships between resources, configuration, and VNF performance, achieving a high R-squared score of {r2:.2%}.")
print("Key Takeaways:")
print("- The model can provide accurate performance predictions, which is essential for resource planning in an NFV environment. This prevents both under-provisioning (which violates SLAs) and over-provisioning (which wastes expensive hardware resources).")
print("- The feature importance plot confirms that `vcpus` is the most critical factor for performance, followed by the `config_complexity` (e.g., number of firewall rules), which acts as a performance penalty. This aligns perfectly with real-world VNF behavior.")
print("- An NFV Orchestrator could use this model as a 'performance oracle'. Before deploying a new VNF for a customer, it could ask the model: 'To guarantee 5 Gbps for a firewall with 2000 rules, what is the minimum number of vCPUs and RAM required?'. The orchestrator could then automatically provision the right-sized VNF, leading to a highly efficient, automated, and SLA-aware cloud platform.")

```