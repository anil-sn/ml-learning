{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47c2c7e",
   "metadata": {},
   "source": [
    "# Project 21: Indoor Localization using Wi-Fi Signal Strength (RSSI)\n",
    "\n",
    "**Objective:** Build a multi-class classification model that can predict a user's specific location (a unique room or space) within a building by using the Received Signal Strength Indicator (RSSI) from numerous nearby Wi-Fi APs.\n",
    "\n",
    "**Dataset Source:** Kaggle - \"UJIIndoorLoc Data Set\" with Wi-Fi fingerprints from 520 different APs\n",
    "\n",
    "**Model:** RandomForestClassifier - excellent for high-dimensional problems with complex non-linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-kaggle",
   "metadata": {},
   "source": [
    "## 1. Setup Kaggle API and Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kaggle-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print(\"--- Setting up Kaggle API ---\")\n",
    "    !pip install -q kaggle\n",
    "    from google.colab import files\n",
    "    print(\"\\nPlease upload your kaggle.json file:\")\n",
    "    uploaded = files.upload()\n",
    "    if 'kaggle.json' not in uploaded:\n",
    "        print(\"\\nError: kaggle.json not uploaded.\")\n",
    "        exit()\n",
    "    !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle.json\n",
    "else:\n",
    "    print(\"Kaggle API already configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Downloading UJIIndoorLoc Dataset from Kaggle ---\")\n",
    "!kaggle datasets download -d ujim-ml/ujiindoorloc\n",
    "\n",
    "print(\"\\n--- Unzipping the dataset ---\")\n",
    "!unzip -q ujiindoorloc.zip -d indoor_loc\n",
    "print(\"Dataset setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-prep",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n--- Loading and Preprocessing Data ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # We will combine the training and validation sets for a standard split\n",
    "    df_train = pd.read_csv('indoor_loc/trainingData.csv')\n",
    "    df_val = pd.read_csv('indoor_loc/validationData.csv')\n",
    "    df = pd.concat([df_train, df_val], ignore_index=True)\n",
    "    print(\"Successfully loaded and combined datasets.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find dataset files. {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Cleaning and Feature Engineering ---\n",
    "# The first 520 columns are the WAP RSSI values\n",
    "wap_cols = [f'WAP{str(i).zfill(3)}' for i in range(1, 521)]\n",
    "# The last 9 columns are metadata about the location\n",
    "loc_cols = ['LONGITUDE', 'LATITUDE', 'FLOOR', 'BUILDINGID', 'SPACEID', 'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
    "\n",
    "# In this dataset, '100' is used to denote 'no signal'. This is problematic for ML.\n",
    "# We will replace it with a very low RSSI value (-105) to maintain the ordinal nature of the data.\n",
    "print(\"Replacing '100' (no signal) with -105 dBm...\")\n",
    "df[wap_cols] = df[wap_cols].replace(100, -105)\n",
    "\n",
    "# --- Create a Unique Location Target ---\n",
    "# We want to predict a specific space. We'll create a composite key for this.\n",
    "df['location'] = df['BUILDINGID'].astype(str) + '-' + df['FLOOR'].astype(str) + '-' + df['SPACEID'].astype(str)\n",
    "print(f\"Created a unique location target. Total unique locations: {df['location'].nunique()}\")\n",
    "print(f\"\\nDataset shape after preprocessing: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-split",
   "metadata": {},
   "source": [
    "## 3. Data Splitting and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Splitting and Encoding Data ---\")\n",
    "\n",
    "X = df[wap_cols]\n",
    "y = df['location']\n",
    "\n",
    "# Encode the string labels for the target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Use a stratified split to ensure all locations are represented proportionally\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-training",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Training ---\")\n",
    "\n",
    "# RandomForest is a great choice for this high-dimensional problem\n",
    "# n_estimators=50 is a good starting point for speed. n_jobs=-1 uses all CPU cores.\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"Training the RandomForestClassifier... (This may take a few minutes)\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-eval",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Evaluation ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nOverall Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# The full classification report is too large to display, so we'll show a sample.\n",
    "# Let's see how it performs on a few specific, randomly chosen locations.\n",
    "print(\"\\nSample Classification Report (for 5 random locations):\")\n",
    "random_labels_indices = np.random.choice(np.unique(y_test), 5, replace=False)\n",
    "random_labels_names = le.inverse_transform(random_labels_indices)\n",
    "print(classification_report(y_test, y_pred, labels=random_labels_indices, target_names=random_labels_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-importance",
   "metadata": {},
   "source": [
    "## 6. Feature Importance: Which APs are Most Important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Feature Importance ---\")\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[-20:] # Top 20 most important APs\n",
    "features = X.columns\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.title('Top 20 Most Important Access Points for Localization')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-time-prediction",
   "metadata": {},
   "source": [
    "## 7. Real-Time Location Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prediction-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_location(rssi_readings):\n",
    "    \"\"\"\n",
    "    Predict indoor location from real-time RSSI readings\n",
    "    \n",
    "    Args:\n",
    "        rssi_readings: Dict of WAP_ID -> RSSI_value\n",
    "    \n",
    "    Returns:\n",
    "        Predicted location string\n",
    "    \"\"\"\n",
    "    # Prepare feature vector with default 'no signal' value\n",
    "    feature_vector = np.full(520, -105)\n",
    "    \n",
    "    # Fill in available RSSI readings\n",
    "    for wap_id, rssi in rssi_readings.items():\n",
    "        if wap_id in wap_cols:\n",
    "            wap_index = wap_cols.index(wap_id)\n",
    "            feature_vector[wap_index] = rssi\n",
    "    \n",
    "    # Predict location\n",
    "    prediction = model.predict([feature_vector])[0]\n",
    "    return le.inverse_transform([prediction])[0]\n",
    "\n",
    "# Example usage\n",
    "example_readings = {\n",
    "    'WAP001': -45,\n",
    "    'WAP002': -68,\n",
    "    'WAP003': -72,\n",
    "    'WAP010': -85\n",
    "}\n",
    "\n",
    "predicted_location = predict_location(example_readings)\n",
    "print(f\"\\nExample prediction for sample RSSI readings: {predicted_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conclusion-notes",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Conclusion ---\")\n",
    "print(f\"The RandomForest model achieved an impressive accuracy of {accuracy:.2%}, demonstrating that Wi-Fi RSSI is a highly effective feature for indoor localization.\")\n",
    "print(\"Key Takeaways:\")\n",
    "print(\"- The model can reliably predict a user's specific room out of hundreds of possibilities, showcasing the stability of Wi-Fi 'fingerprints'.\")\n",
    "print(\"- The Feature Importance plot provides extremely valuable operational insights. It shows which specific Access Points are the most critical for location services. A network administrator could use this information to ensure these key APs have high uptime and are not moved or decommissioned without careful planning.\")\n",
    "print(\"- This technology is the backbone of many modern services, including indoor navigation (e.g., in airports or malls), location-aware advertising, and asset tracking within a warehouse or hospital.\")\n",
    "print(\"- By correctly preprocessing the 'no signal' value (100 -> -105), we provided the model with meaningful data that significantly improved its ability to learn.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}