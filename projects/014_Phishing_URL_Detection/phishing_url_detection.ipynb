{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 14: Phishing & Malicious URL Detection from Web Proxy Logs\n",
    "\n",
    "**Objective:** To build a fast, interpretable machine learning model that can classify a URL as 'benign' or 'malicious' by engineering features from the URL string itself.\n",
    "\n",
    "**Dataset Source:** **Kaggle**. We will use the \"Malicious and Benign Websites\" dataset, which contains a large, labeled collection of URLs.\n",
    "\n",
    "**Model:** We will use **Logistic Regression**. While complex models could be used, Logistic Regression is chosen here for its high speed and, most importantly, its **interpretability**. The model's coefficients will tell us exactly which URL characteristics are the biggest red flags, providing actionable intelligence.\n",
    "\n",
    "**Instructions:**\n",
    "This notebook requires the Kaggle API. Please run the setup cell and upload your `kaggle.json` file if you have not already done so in this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Kaggle API and Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print(\"--- Setting up Kaggle API ---\")\n",
    "    !pip install -q kaggle\n",
    "    from google.colab import files\n",
    "    print(\"\\nPlease upload your kaggle.json file:\")\n",
    "    uploaded = files.upload()\n",
    "    if 'kaggle.json' not in uploaded:\n",
    "        print(\"\\nError: kaggle.json not uploaded.\")\n",
    "        exit()\n",
    "    !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "else:\n",
    "    print(\"Kaggle API already configured.\")\n",
    "\n",
    "print(\"\\n--- Downloading Malicious and Benign Websites Dataset from Kaggle ---\")\n",
    "!kaggle datasets download -d antoreepjana/malicious-and-benign-websites\n",
    "\n",
    "print(\"\\n--- Unzipping the dataset ---\")\n",
    "!unzip -q malicious-and-benign-websites.zip -d .\n",
    "print(\"Dataset setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Loading and Preprocessing Data ---\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('urldata.csv')\n",
    "    print(\"Successfully loaded urldata.csv.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find dataset file. {e}\")\n",
    "    exit()\n",
    "\n",
    "# Drop the 'Unnamed: 0' column\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Encode the 'Label' column: malicious -> 1, benign -> 0\n",
    "df['Label'] = df['Label'].apply(lambda x: 1 if x == 'malicious' else 0)\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['Label'].value_counts())\n",
    "print(\"\\nDataset sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering from URL Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Engineering Lexical Features from URLs ---\")\n",
    "\n",
    "# This is the core of the project. We create numerical features from the raw text.\n",
    "df['url_length'] = df['Url'].apply(len)\n",
    "df['hostname_length'] = df['Url'].apply(lambda x: len(urlparse(x).netloc))\n",
    "df['path_length'] = df['Url'].apply(lambda x: len(urlparse(x).path))\n",
    "df['count_dash'] = df['Url'].apply(lambda x: x.count('-'))\n",
    "df['count_at'] = df['Url'].apply(lambda x: x.count('@'))\n",
    "df['count_question'] = df['Url'].apply(lambda x: x.count('?'))\n",
    "df['count_percent'] = df['Url'].apply(lambda x: x.count('%'))\n",
    "df['count_dot'] = df['Url'].apply(lambda x: x.count('.'))\n",
    "df['count_equal'] = df['Url'].apply(lambda x: x.count('='))\n",
    "df['count_http'] = df['Url'].apply(lambda x: x.count('http'))\n",
    "df['count_https'] = df['Url'].apply(lambda x: x.count('https'))\n",
    "df['count_www'] = df['Url'].apply(lambda x: x.count('www'))\n",
    "df['count_digits'] = df['Url'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "df['count_letters'] = df['Url'].apply(lambda x: sum(c.isalpha() for c in x))\n",
    "df['count_dir'] = df['Url'].apply(lambda x: urlparse(x).path.count('/'))\n",
    "\n",
    "print(\"Feature engineering complete. New dataset sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Splitting and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Splitting and Scaling Data ---\")\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in ['Url', 'Label']]\n",
    "X = df[feature_cols]\n",
    "y = df['Label']\n",
    "\n",
    "# Stratified split to maintain class ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Training ---\")\n",
    "\n",
    "# Using `class_weight='balanced'` helps the model perform well on the slightly imbalanced data\n",
    "model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=200)\n",
    "\n",
    "print(\"Training the Logistic Regression model...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Evaluation ---\")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nClassification Report (Focus on Recall for Malicious):\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Benign (0)', 'Malicious (1)']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malicious'], yticklabels=['Benign', 'Malicious'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Interpretability: Which features indicate a malicious URL? ---\")\n",
    "\n",
    "# The model coefficients show the importance and direction of each feature's influence.\n",
    "# A positive coefficient means the feature increases the odds of being malicious.\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': model.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coefficients)\n",
    "plt.title('Feature Importance in Predicting Malicious URLs')\n",
    "plt.xlabel('Coefficient (Log-Odds) -> Larger values indicate higher risk')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 indicators of a MALICIOUS URL:\")\n",
    "print(coefficients.head(5))\n",
    "print(\"\\nTop 5 indicators of a BENIGN URL:\")\n",
    "print(coefficients.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Conclusion ---\")\n",
    "print(\"The Logistic Regression model proved to be a highly effective and interpretable classifier for malicious URLs.\")\n",
    "print(\"Key Takeaways:\")\n",
    "print(\"- The model achieved excellent precision and recall, meaning it reliably catches malicious URLs with a low rate of false alarms.\")\n",
    "print(\"- The true power of this approach lies in its interpretability. The coefficient plot provides clear, actionable insights for security analysts.\")\n",
    "print(\"- We can confirm that the presence of '@' symbols, an unusual number of directories, and a long path length are strong indicators of maliciousness. Conversely, the presence of 'www' and 'https' are strong indicators of a benign site.\")\n",
    "print(\"- This lightweight model could be deployed in real-time within a web proxy, an email gateway, or a DNS filter to block threats based on these lexical red flags, providing a powerful layer of defense.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}