{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "project-header",
   "metadata": {},
   "source": [
    "# Project 30: Virtual Network Function (VNF) Performance Prediction\n",
    "\n",
    "**Objective:** Build a regression model that can predict the maximum achievable throughput (in Gbps) of a VNF based on its type, allocated resources (vCPUs, RAM), and workload characteristics.\n",
    "\n",
    "**Dataset Source:** Synthetically Generated (realistic VNF performance data)\n",
    "\n",
    "**Model:** XGBoost Regressor for capturing complex non-linear relationships between resource allocation and VNF performance\n",
    "\n",
    "**Instructions:**\n",
    "This notebook is fully self-contained and does not require external files. Simply run all cells in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Project 30: VNF Performance Prediction - Setup and Imports\n",
    "# ==================================================================================\n",
    "\n",
    "# Install XGBoost if not already installed\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError:\n",
    "    print(\"Installing XGBoost...\")\n",
    "    !pip install -q xgboost\n",
    "    import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Synthetic VNF Performance Data Generation\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Generating Synthetic VNF Performance Dataset ---\")\n",
    "\n",
    "num_samples = 3000\n",
    "data = []\n",
    "vnf_types = ['Firewall', 'Router', 'LoadBalancer', 'IDS']\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    vnf_type = random.choice(vnf_types)\n",
    "    vcpus = random.randint(2, 16)\n",
    "    ram_gb = random.choice([4, 8, 16, 32])\n",
    "    \n",
    "    # Configuration complexity affects performance\n",
    "    if vnf_type == 'Firewall':\n",
    "        config_complexity = np.random.randint(100, 5000)  # Number of rules\n",
    "    elif vnf_type == 'IDS':\n",
    "        config_complexity = np.random.randint(500, 10000)  # Number of signatures\n",
    "    else:\n",
    "        config_complexity = np.random.randint(10, 100)  # e.g., number of routes/VIPs\n",
    "\n",
    "    # --- Performance Formula ---\n",
    "    # Base performance is driven by vCPUs (primary factor) and RAM (secondary)\n",
    "    base_throughput = (vcpus * 1.5) + (ram_gb * 0.2)\n",
    "    \n",
    "    # Complexity introduces a performance penalty (non-linear)\n",
    "    complexity_penalty = np.log1p(config_complexity) * 0.5\n",
    "    if vnf_type in ['Firewall', 'IDS']:\n",
    "        complexity_penalty *= 1.5  # These are more sensitive to complexity\n",
    "    \n",
    "    # Add random noise\n",
    "    random_noise = np.random.normal(0, 0.5)\n",
    "    \n",
    "    # Calculate final throughput\n",
    "    throughput_gbps = base_throughput - complexity_penalty + random_noise\n",
    "    throughput_gbps = max(1, throughput_gbps)  # Ensure a minimum performance\n",
    "    \n",
    "    data.append([vnf_type, vcpus, ram_gb, config_complexity, throughput_gbps])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['vnf_type', 'vcpus', 'ram_gb', 'config_complexity', 'throughput_gbps'])\n",
    "print(f\"Dataset generation complete. Created {len(df)} samples.\")\n",
    "print(\"\\nDataset Sample:\")\n",
    "print(df.sample(10))\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nVNF Type Distribution:\")\n",
    "print(df['vnf_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Data Preprocessing and Encoding\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Data Preprocessing and Encoding ---\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['throughput_gbps'])\n",
    "y = df['throughput_gbps']\n",
    "\n",
    "print(f\"Original feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "\n",
    "# One-hot encode the 'vnf_type' categorical feature\n",
    "X_encoded = pd.get_dummies(X, columns=['vnf_type'], drop_first=True)\n",
    "\n",
    "print(f\"\\nAfter encoding, feature matrix shape: {X_encoded.shape}\")\n",
    "print(f\"Encoded columns: {list(X_encoded.columns)}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(\"Data preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Model Training with XGBoost Regressor\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Model Training ---\")\n",
    "\n",
    "# Initialize XGBoost Regressor with optimized parameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training the XGBoost Regressor model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Display model parameters\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"• Number of estimators: {model.n_estimators}\")\n",
    "print(f\"• Learning rate: {model.learning_rate}\")\n",
    "print(f\"• Max depth: {model.max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Model Evaluation\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Model Evaluation ---\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Performance Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.3f} Gbps\")\n",
    "print(f\"  (On average, the model's throughput prediction is off by ±{mae:.3f} Gbps)\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.3f} Gbps\")\n",
    "print(f\"R-squared (R²): {r2:.3f}\")\n",
    "print(f\"  ({r2:.1%} of the variance in throughput can be explained by our features)\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "mean_actual = np.mean(y_test)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(f\"\\nAdditional Metrics:\")\n",
    "print(f\"Mean Actual Throughput: {mean_actual:.3f} Gbps\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Results Visualization\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Results Visualization ---\")\n",
    "\n",
    "# Create subplots for comprehensive visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs. Predicted scatter plot\n",
    "ax1.scatter(y_test, y_pred, alpha=0.6, color='blue')\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Perfect Prediction')\n",
    "ax1.set_xlabel('Actual Throughput (Gbps)')\n",
    "ax1.set_ylabel('Predicted Throughput (Gbps)')\n",
    "ax1.set_title('Actual vs. Predicted VNF Throughput')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals plot\n",
    "residuals = y_test - y_pred\n",
    "ax2.scatter(y_pred, residuals, alpha=0.6, color='green')\n",
    "ax2.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Predicted Throughput (Gbps)')\n",
    "ax2.set_ylabel('Residuals (Actual - Predicted)')\n",
    "ax2.set_title('Residuals Plot')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature importance (using XGBoost's built-in plot)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_encoded.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "ax3.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "ax3.set_xlabel('Feature Importance')\n",
    "ax3.set_title('Feature Importance in VNF Performance Prediction')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Distribution of predictions vs actual\n",
    "ax4.hist(y_test, bins=30, alpha=0.7, label='Actual', color='blue')\n",
    "ax4.hist(y_pred, bins=30, alpha=0.7, label='Predicted', color='red')\n",
    "ax4.set_xlabel('Throughput (Gbps)')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Distribution: Actual vs Predicted Throughput')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display feature importance table\n",
    "print(\"\\n--- Feature Importance: What drives VNF performance? ---\")\n",
    "feature_importance_sorted = feature_importance.sort_values('importance', ascending=False)\n",
    "print(feature_importance_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-prediction-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Performance Prediction Examples\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Performance Prediction Examples ---\")\n",
    "\n",
    "# Create example VNF configurations for prediction\n",
    "example_configs = [\n",
    "    {'vnf_type': 'Firewall', 'vcpus': 4, 'ram_gb': 8, 'config_complexity': 1000},\n",
    "    {'vnf_type': 'Firewall', 'vcpus': 8, 'ram_gb': 16, 'config_complexity': 1000},\n",
    "    {'vnf_type': 'Router', 'vcpus': 4, 'ram_gb': 8, 'config_complexity': 50},\n",
    "    {'vnf_type': 'LoadBalancer', 'vcpus': 6, 'ram_gb': 16, 'config_complexity': 20},\n",
    "    {'vnf_type': 'IDS', 'vcpus': 8, 'ram_gb': 32, 'config_complexity': 5000}\n",
    "]\n",
    "\n",
    "# Convert to DataFrame and encode\n",
    "examples_df = pd.DataFrame(example_configs)\n",
    "examples_encoded = pd.get_dummies(examples_df, columns=['vnf_type'], drop_first=True)\n",
    "\n",
    "# Ensure all columns from training are present\n",
    "for col in X_encoded.columns:\n",
    "    if col not in examples_encoded.columns:\n",
    "        examples_encoded[col] = 0\n",
    "\n",
    "# Reorder columns to match training data\n",
    "examples_encoded = examples_encoded[X_encoded.columns]\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(examples_encoded)\n",
    "\n",
    "print(\"\\nVNF Performance Predictions:\")\n",
    "print(\"=\" * 80)\n",
    "for i, (config, pred) in enumerate(zip(example_configs, predictions)):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  VNF Type: {config['vnf_type']}\")\n",
    "    print(f\"  vCPUs: {config['vcpus']}, RAM: {config['ram_gb']} GB\")\n",
    "    print(f\"  Config Complexity: {config['config_complexity']}\")\n",
    "    print(f\"  Predicted Throughput: {pred:.2f} Gbps\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Conclusion\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Conclusion ---\")\n",
    "print(f\"The XGBoost model successfully learned the complex relationships between resources, configuration, and VNF performance, achieving an R² score of {r2:.3f}.\")\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(f\"• Total VNF configurations analyzed: {len(df):,}\")\n",
    "print(f\"• Average prediction error: ±{mae:.3f} Gbps\")\n",
    "print(f\"• Model explains {r2:.1%} of throughput variance\")\n",
    "print(f\"• Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "print(\"\\nBusiness Impact:\")\n",
    "print(\"• The model provides accurate performance predictions essential for resource planning in NFV environments\")\n",
    "print(\"• Prevents both under-provisioning (SLA violations) and over-provisioning (resource waste)\")\n",
    "print(\"• Feature importance confirms that vCPUs are the most critical factor for performance\")\n",
    "print(\"• Configuration complexity acts as a significant performance penalty, especially for security VNFs\")\n",
    "\n",
    "print(\"\\nReal-world Application:\")\n",
    "print(\"• NFV Orchestrators can use this model as a 'performance oracle'\")\n",
    "print(\"• Before deploying VNFs, ask: 'What resources are needed to guarantee X Gbps?'\")\n",
    "print(\"• Enables automatic right-sizing of VNF deployments\")\n",
    "print(\"• Leads to highly efficient, automated, and SLA-aware cloud platforms\")\n",
    "\n",
    "print(\"\\nTechnical Validation:\")\n",
    "print(\"• The model correctly captures the non-linear relationship between configuration complexity and performance\")\n",
    "print(\"• Resource scaling effects are accurately modeled with vCPUs having the highest impact\")\n",
    "print(\"• Performance penalties for complex configurations align with real-world VNF behavior\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}