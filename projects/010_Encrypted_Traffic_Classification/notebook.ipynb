{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 10: Encrypted Traffic Classification\n",
    "\n",
    "**Objective:** To build a machine learning model that can classify different types of application traffic (Chat, File Transfer, Streaming, etc.) even when it is encrypted within a VPN tunnel.\n",
    "\n",
    "**Dataset Source:** Kaggle - \"ISCX VPN-nonVPN Dataset\" from the University of New Brunswick, a benchmark for this task. It contains pre-extracted statistical features from thousands of network flows.\n",
    "\n",
    "**Model:** XGBoost (Extreme Gradient Boosting) - a highly optimized and powerful gradient boosting library that consistently delivers state-of-the-art results on tabular data like this.\n",
    "\n",
    "**Instructions:**\n",
    "This notebook requires the Kaggle API. Please run the setup cell and upload your `kaggle.json` file if you have not already done so in this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Kaggle API and Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print(\"--- Setting up Kaggle API ---\")\n",
    "    !pip install -q kaggle\n",
    "    from google.colab import files\n",
    "    print(\"\\nPlease upload your kaggle.json file:\")\n",
    "    uploaded = files.upload()\n",
    "    if 'kaggle.json' not in uploaded:\n",
    "        print(\"\\nError: kaggle.json not uploaded.\")\n",
    "        exit()\n",
    "    !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "else:\n",
    "    print(\"Kaggle API already configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Downloading ISCX VPN-nonVPN Dataset from Kaggle ---\")\n",
    "!kaggle datasets download -d jsphyg/vpn-non-vpn-dataset\n",
    "\n",
    "print(\"\\n--- Unzipping the dataset ---\")\n",
    "!unzip -q vpn-non-vpn-dataset.zip -d vpn_dataset\n",
    "print(\"Dataset setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Loading and Preprocessing Data ---\")\n",
    "\n",
    "# Define the types of traffic we want to classify\n",
    "# We'll focus on the VPN traffic for this demonstration\n",
    "traffic_types = ['vpn_chat', 'vpn_file', 'vpn_email', 'vpn_streaming', 'vpn_voip']\n",
    "data_path = 'vpn_dataset/vpn'\n",
    "\n",
    "# Load and label each CSV file\n",
    "df_list = []\n",
    "for traffic_type in traffic_types:\n",
    "    # Use glob to find the exact CSV file (e.g., vpn_file_transfer.csv)\n",
    "    file_pattern = os.path.join(data_path, f\"{traffic_type}*.csv\")\n",
    "    try:\n",
    "        csv_file = glob.glob(file_pattern)[0]\n",
    "        temp_df = pd.read_csv(csv_file)\n",
    "        # Use a simplified label for the class\n",
    "        temp_df['label'] = traffic_type.split('_')[1] # e.g., 'chat', 'file'\n",
    "        df_list.append(temp_df)\n",
    "        print(f\"Loaded {os.path.basename(csv_file)} with label '{temp_df['label'].iloc[0]}'\")\n",
    "    except (FileNotFoundError, IndexError):\n",
    "        print(f\"Warning: Could not find or load CSV for {traffic_type}\")\n",
    "\n",
    "# Combine into a single dataframe\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(f\"\\nCombined dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Cleaning ---\n",
    "# The dataset may have column names with leading spaces\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"\\nCleaned column names.\")\n",
    "\n",
    "# Drop columns that are not useful features or are identifiers\n",
    "columns_to_drop = ['Flow ID', 'Src IP', 'Dst IP', 'Src Port', 'Dst Port', 'Timestamp']\n",
    "# Only drop columns that actually exist in the dataframe\n",
    "columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n",
    "\n",
    "# Handle infinite values and NaNs which are common in flow stats\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(f\"Dropped NaN/infinite values. Shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of our new labels\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Splitting Data for Training and Testing ---\")\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Encode the string labels into integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Stratified split to maintain class proportions in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Training ---\")\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "# `objective='multi:softmax'` is used for multi-class classification.\n",
    "# `use_label_encoder=False` and `eval_metric='mlogloss'` are modern standards.\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(le.classes_),\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training the XGBoost model... (This may take a few minutes)\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Evaluation ---\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The Classification Report shows precision, recall, and f1-score for each class.\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Confusion Matrix visualizes where the model is making mistakes.\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix for Encrypted Traffic')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Feature Importance ---\")\n",
    "\n",
    "# XGBoost has a built-in function to plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "xgb.plot_importance(model, ax=ax, max_num_features=15, height=0.8)\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "The XGBoost model successfully learned to distinguish between different types of encrypted application traffic with high accuracy.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- This demonstrates that it's possible to manage and classify network traffic without decrypting it, which is crucial for privacy and security.\n",
    "- The Confusion Matrix shows the model is highly accurate, with most confusion happening between similar traffic types (if any).\n",
    "- The Feature Importance plot is very insightful. It highlights that metrics like 'Fwd Packet Length Mean', 'Flow Duration', and 'Packet Length Variance' are powerful differentiators. This makes sense intuitively: streaming traffic (long flows, large consistent packets) looks very different from chat traffic (short flows, small bursty packets).\n",
    "- Network engineers can use such a model for Quality of Service (QoS) to prioritize latency-sensitive traffic (like VoIP) or for security to detect anomalous encrypted flows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}