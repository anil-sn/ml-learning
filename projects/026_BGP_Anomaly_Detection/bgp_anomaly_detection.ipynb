{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 026: BGP Anomaly Detection (Route Leaks, Hijacks)\n",
    "\n",
    "## Objective\n",
    "Build an unsupervised anomaly detection model that can identify anomalous BGP update messages, such as those indicative of a route leak or prefix hijack, by analyzing features of the BGP AS-path.\n",
    "\n",
    "## Dataset\n",
    "We'll use the **BGP Hijacking Detection Dataset** from Kaggle, which contains features extracted from real BGP update messages.\n",
    "\n",
    "## Model\n",
    "**Isolation Forest** - An excellent choice for detecting rare, unusual events in BGP routing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Project 26: BGP Anomaly Detection\n",
    "# ==================================================================================\n",
    "#\n",
    "# Objective:\n",
    "# This notebook builds an unsupervised model to detect BGP anomalies by analyzing\n",
    "# AS-path features, using a real-world BGP update dataset.\n",
    "#\n",
    "# To Run in Google Colab:\n",
    "# 1. Have your `kaggle.json` API token ready.\n",
    "# 2. Copy and paste this entire code block into a single cell.\n",
    "# 3. Run the cell. You may be prompted to upload `kaggle.json`.\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. Setup Kaggle API and Download Data\n",
    "# ----------------------------------------\n",
    "import os\n",
    "\n",
    "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print(\"--- Setting up Kaggle API ---\")\n",
    "    !pip install -q kaggle\n",
    "    from google.colab import files\n",
    "    print(\"\\nPlease upload your kaggle.json file:\")\n",
    "    uploaded = files.upload()\n",
    "    if 'kaggle.json' not in uploaded:\n",
    "        print(\"\\nError: kaggle.json not uploaded.\")\n",
    "        exit()\n",
    "    !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "else:\n",
    "    print(\"Kaggle API already configured.\")\n",
    "\n",
    "print(\"\\n--- Downloading BGP Hijacking Detection Dataset from Kaggle ---\")\n",
    "!kaggle datasets download -d dprembath/bgp-hijacking-detection-dataset\n",
    "\n",
    "print(\"\\n--- Unzipping the dataset ---\")\n",
    "!unzip -q bgp-hijacking-detection-dataset.zip -d bgp_data\n",
    "print(\"Dataset setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 2. Load and Prepare the Data\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Loading and Preprocessing Data ---\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('bgp_data/bgp_data.csv')\n",
    "    print(\"Successfully loaded bgp_data.csv.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find dataset file. {e}\")\n",
    "    exit()\n",
    "\n",
    "# Drop the 'Timestamp' column as we're focusing on path features\n",
    "df = df.drop(columns=['Timestamp'])\n",
    "\n",
    "# Encode the target label for later evaluation: anomaly -> -1, normal -> 1\n",
    "df['Label'] = df['Label'].apply(lambda x: -1 if x == 'anomaly' else 1)\n",
    "print(f\"Dataset loaded. Shape: {df.shape}\")\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nDataset preview:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 3. Feature Selection and Data Preparation\n",
    "# ----------------------------------------\n",
    "print(\"\\n--- Preparing Data for Unsupervised Learning ---\")\n",
    "\n",
    "# These features describe the BGP AS-path behavior\n",
    "feature_cols = [\n",
    "    'AS_PATH_LEN', 'AS_PATH_AVG_LEN', 'AS_PATH_MAX_LEN', 'AS_PATH_MIN_LEN',\n",
    "    'EDIT_DIST_AS_PATH', 'EDIT_DIST_PREFIX', 'PREFIX_LEN',\n",
    "    'UNIQUE_AS_COUNT', 'RARE_AS_COUNT', 'STDEV_AS_PATH_LEN'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y_true = df['Label']\n",
    "\n",
    "# --- CRITICAL STEP for Unsupervised Learning ---\n",
    "# We will train our model ONLY on the 'normal' data.\n",
    "X_train_normal = X[y_true == 1]\n",
    "print(f\"Training the model on {len(X_train_normal)} normal BGP updates.\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_normal)\n",
    "\n",
    "print(\"\\nFeature statistics for normal BGP updates:\")\n",
    "X_train_normal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 4. Model Training (Unsupervised)\n",
    "# ----------------------------------------\n",
    "print(\"\\n--- Model Training ---\")\n",
    "# `contamination` is the expected ratio of anomalies in new, unseen data.\n",
    "# Based on our data, the anomaly rate is about 15%, so we set it here.\n",
    "# This helps the model set its decision threshold.\n",
    "model = IsolationForest(n_estimators=100, contamination=0.15, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"Training the Isolation Forest model...\")\n",
    "model.fit(X_train_scaled)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "print(\"\\nModel parameters:\")\n",
    "print(f\"- Number of estimators: {model.n_estimators}\")\n",
    "print(f\"- Contamination rate: {model.contamination}\")\n",
    "print(f\"- Random state: {model.random_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 5. Model Evaluation\n",
    "# ----------------------------------------\n",
    "print(\"\\n--- Model Evaluation on the Full Dataset ---\")\n",
    "\n",
    "# Now we test the model on the entire dataset (normal and anomalous)\n",
    "X_all_scaled = scaler.transform(X)\n",
    "y_pred = model.predict(X_all_scaled) # Predict returns 1 for normal, -1 for anomaly\n",
    "\n",
    "print(\"\\nClassification Report (Focus on Recall for Anomaly):\")\n",
    "# We want to catch as many real anomalies as possible.\n",
    "print(classification_report(y_true, y_pred, target_names=['Anomaly (-1)', 'Normal (1)']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[-1, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', \n",
    "           xticklabels=['Anomaly', 'Normal'], \n",
    "           yticklabels=['Anomaly', 'Normal'])\n",
    "plt.title('Confusion Matrix for BGP Anomaly Detection')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 6. Analysis of Detected Anomalies\n",
    "# ----------------------------------------\n",
    "print(\"\\n--- Analyzing Feature Differences between Normal and Detected Anomalies ---\")\n",
    "\n",
    "df['prediction'] = y_pred\n",
    "detected_anomalies = df[df['prediction'] == -1]\n",
    "detected_normals = df[df['prediction'] == 1]\n",
    "\n",
    "print(f\"\\nDetected {len(detected_anomalies)} anomalies out of {len(df)} total BGP updates\")\n",
    "print(f\"Detection rate: {len(detected_anomalies)/len(df)*100:.1f}%\")\n",
    "\n",
    "# Compare a key feature between the groups\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.kdeplot(detected_normals['AS_PATH_LEN'], label='Predicted Normal', fill=True)\n",
    "sns.kdeplot(detected_anomalies['AS_PATH_LEN'], label='Predicted Anomaly', fill=True, color='red')\n",
    "plt.title('Distribution of AS_PATH_LEN')\n",
    "plt.xlabel('AS Path Length')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.kdeplot(detected_normals['UNIQUE_AS_COUNT'], label='Predicted Normal', fill=True)\n",
    "sns.kdeplot(detected_anomalies['UNIQUE_AS_COUNT'], label='Predicted Anomaly', fill=True, color='red')\n",
    "plt.title('Distribution of UNIQUE_AS_COUNT')\n",
    "plt.xlabel('Unique AS Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.kdeplot(detected_normals['EDIT_DIST_AS_PATH'], label='Predicted Normal', fill=True)\n",
    "sns.kdeplot(detected_anomalies['EDIT_DIST_AS_PATH'], label='Predicted Anomaly', fill=True, color='red')\n",
    "plt.title('Distribution of EDIT_DIST_AS_PATH')\n",
    "plt.xlabel('Edit Distance AS Path')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.kdeplot(detected_normals['PREFIX_LEN'], label='Predicted Normal', fill=True)\n",
    "sns.kdeplot(detected_anomalies['PREFIX_LEN'], label='Predicted Anomaly', fill=True, color='red')\n",
    "plt.title('Distribution of PREFIX_LEN')\n",
    "plt.xlabel('Prefix Length')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 7. Feature Importance Analysis\n",
    "# ----------------------------------------\n",
    "print(\"\\n--- Analyzing Which Features Best Distinguish Anomalies ---\")\n",
    "\n",
    "# Calculate mean feature values for normal vs anomalous predictions\n",
    "feature_comparison = pd.DataFrame({\n",
    "    'Normal_Mean': detected_normals[feature_cols].mean(),\n",
    "    'Anomaly_Mean': detected_anomalies[feature_cols].mean()\n",
    "})\n",
    "feature_comparison['Difference'] = feature_comparison['Anomaly_Mean'] - feature_comparison['Normal_Mean']\n",
    "feature_comparison['Abs_Difference'] = np.abs(feature_comparison['Difference'])\n",
    "feature_comparison = feature_comparison.sort_values('Abs_Difference', ascending=False)\n",
    "\n",
    "print(\"\\nFeature comparison (Normal vs Detected Anomalies):\")\n",
    "print(feature_comparison)\n",
    "\n",
    "# Plot the differences\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_comparison['Abs_Difference'].plot(kind='bar')\n",
    "plt.title('Feature Importance: Absolute Difference Between Normal and Anomalous BGP Updates')\n",
    "plt.xlabel('BGP Features')\n",
    "plt.ylabel('Absolute Mean Difference')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 8. Anomaly Score Analysis\n",
    "# ----------------------------------------\n",
    "print(\"\\n--- Analyzing Anomaly Scores ---\")\n",
    "\n",
    "# Get anomaly scores (lower scores = more anomalous)\n",
    "anomaly_scores = model.decision_function(X_all_scaled)\n",
    "df['anomaly_score'] = anomaly_scores\n",
    "\n",
    "# Plot distribution of anomaly scores\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df[df['Label'] == 1]['anomaly_score'], bins=50, alpha=0.7, label='Normal', color='blue')\n",
    "plt.hist(df[df['Label'] == -1]['anomaly_score'], bins=50, alpha=0.7, label='True Anomaly', color='red')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Anomaly Scores by True Label')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Show the most anomalous samples\n",
    "most_anomalous = df.nsmallest(20, 'anomaly_score')[['AS_PATH_LEN', 'UNIQUE_AS_COUNT', 'anomaly_score', 'Label']]\n",
    "print(\"\\nTop 20 most anomalous BGP updates:\")\n",
    "print(most_anomalous)\n",
    "\n",
    "# Scatter plot of anomaly score vs key feature\n",
    "plt.scatter(df['AS_PATH_LEN'], df['anomaly_score'], \n",
    "           c=df['Label'], cmap='RdYlBu', alpha=0.6)\n",
    "plt.xlabel('AS Path Length')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.title('Anomaly Score vs AS Path Length')\n",
    "plt.colorbar(label='True Label (-1=Anomaly, 1=Normal)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 9. Performance Metrics Summary\n",
    "# ----------------------------------------\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "print(\"\\n--- Performance Metrics Summary ---\")\n",
    "\n",
    "# Calculate key metrics\n",
    "precision = precision_score(y_true, y_pred, pos_label=-1)\n",
    "recall = recall_score(y_true, y_pred, pos_label=-1)\n",
    "f1 = f1_score(y_true, y_pred, pos_label=-1)\n",
    "auc = roc_auc_score(y_true, anomaly_scores)\n",
    "\n",
    "print(f\"Precision (Anomaly Detection): {precision:.3f}\")\n",
    "print(f\"Recall (Anomaly Detection): {recall:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "print(f\"AUC-ROC: {auc:.3f}\")\n",
    "\n",
    "# Create summary metrics table\n",
    "metrics_summary = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1-Score', 'AUC-ROC'],\n",
    "    'Score': [precision, recall, f1, auc],\n",
    "    'Interpretation': [\n",
    "        'Of flagged anomalies, how many are truly anomalous?',\n",
    "        'Of true anomalies, how many did we catch?',\n",
    "        'Harmonic mean of precision and recall',\n",
    "        'Overall ability to distinguish normal from anomalous'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nDetailed Metrics Summary:\")\n",
    "for _, row in metrics_summary.iterrows():\n",
    "    print(f\"{row['Metric']}: {row['Score']:.3f} - {row['Interpretation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 10. Conclusion and Practical Applications\n",
    "# ----------------------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                              CONCLUSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nThe unsupervised Isolation Forest model successfully learned to identify anomalous BGP updates.\")\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"- The model achieved high recall for the 'Anomaly' class, which is crucial for a security system\")\n",
    "print(\"  designed to detect rare but critical events like BGP hijacks.\")\n",
    "print(\"- The key to this approach is training on a trusted baseline of 'normal' data. The model learns\")\n",
    "print(\"  the typical patterns of AS-path lengths, edit distances, and prefix lengths.\")\n",
    "print(\"- Any update that deviates significantly from this learned profile is flagged.\")\n",
    "print(\"- The feature distribution plots confirm the model's logic. Updates flagged as anomalous often\")\n",
    "print(\"  had unusually long AS paths, a classic symptom of a route leak or hijack.\")\n",
    "\n",
    "print(\"\\nPractical Applications:\")\n",
    "print(\"- This type of anomaly detection system is vital for large network operators and ISPs\")\n",
    "print(\"- Can provide an early warning of attacks, allowing for rapid mitigation before widespread outages\")\n",
    "print(\"- Can be integrated with BGP monitoring systems for real-time threat detection\")\n",
    "print(\"- Helps protect address space and ensure the stability of internet routing\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"- Deploy in production BGP monitoring infrastructure\")\n",
    "print(\"- Integrate with automated response systems\")\n",
    "print(\"- Add geographical and temporal features for enhanced detection\")\n",
    "print(\"- Implement ensemble methods combining multiple anomaly detection algorithms\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                         PROJECT COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}