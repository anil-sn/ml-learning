{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "project-header",
   "metadata": {},
   "source": [
    "# Project 2: Basic Anomaly Detection in Network Logs\n",
    "\n",
    "**Objective:** To identify anomalous sequences of events in system logs using unsupervised machine learning (Isolation Forest).\n",
    "\n",
    "**Dataset Source:** Kaggle - HDFS Log Anomaly Detection Dataset\n",
    "\n",
    "**Model:** Isolation Forest with TF-IDF feature extraction\n",
    "\n",
    "**Instructions:**\n",
    "1. Upload your `kaggle.json` file when prompted\n",
    "2. Run all cells in sequence\n",
    "3. Analyze the unsupervised anomaly detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kaggle-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Project 2: Basic Anomaly Detection in Network Logs - Setup\n",
    "# ==================================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if kaggle.json already exists to avoid re-uploading\n",
    "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print(\"--- Setting up Kaggle API ---\")\n",
    "\n",
    "    # Install the Kaggle library\n",
    "    !pip install -q kaggle\n",
    "\n",
    "    # For Google Colab - prompt user to upload their kaggle.json file\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"\\nPlease upload your kaggle.json file:\")\n",
    "        uploaded = files.upload()\n",
    "\n",
    "        # Check if the file was uploaded\n",
    "        if 'kaggle.json' not in uploaded:\n",
    "            print(\"\\nError: kaggle.json not uploaded. Please restart the cell and upload the file.\")\n",
    "            raise SystemExit\n",
    "\n",
    "        print(\"\\nkaggle.json uploaded successfully.\")\n",
    "\n",
    "        # Create the .kaggle directory and move the json file there\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "    except ImportError:\n",
    "        print(\"Not running in Google Colab. Please ensure kaggle.json is in ~/.kaggle/\")\n",
    "else:\n",
    "    print(\"Kaggle API already configured.\")\n",
    "\n",
    "print(\"\\n--- Downloading HDFS Log Dataset from Kaggle ---\")\n",
    "# Download the dataset\n",
    "!kaggle datasets download -d logpai/hdfs-log-anomaly-detection\n",
    "\n",
    "print(\"\\n--- Unzipping the dataset ---\")\n",
    "# Unzip the downloaded file\n",
    "!unzip -q hdfs-log-anomaly-detection.zip -d .\n",
    "\n",
    "print(\"\\nDataset setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Load and Preprocess the Log Data\n",
    "# ==================================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"--- Loading and Preprocessing Data ---\")\n",
    "\n",
    "# Load the ground truth labels\n",
    "try:\n",
    "    labels_df = pd.read_csv('anomaly_label.csv')\n",
    "    print(\"Loaded anomaly_label.csv successfully.\")\n",
    "    print(f\"Labels dataset shape: {labels_df.shape}\")\n",
    "    print(\"Label distribution:\", labels_df['Label'].value_counts())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: anomaly_label.csv not found.\")\n",
    "    raise\n",
    "\n",
    "# Load the raw log file\n",
    "try:\n",
    "    with open('HDFS.log', 'r') as f:\n",
    "        logs = f.readlines()\n",
    "    print(f\"\\nLoaded HDFS.log successfully. Total lines: {len(logs)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: HDFS.log not found.\")\n",
    "    raise\n",
    "\n",
    "# Display sample log entries\n",
    "print(\"\\nSample log entries:\")\n",
    "for i, line in enumerate(logs[:3]):\n",
    "    print(f\"{i+1}: {line.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "log-parsing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Log Parsing and Session Grouping\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Log Parsing ---\")\n",
    "\n",
    "# Function to parse a raw log line and extract the block ID and log content\n",
    "def parse_log_line(line):\n",
    "    match = re.search(r'(blk_[-]?\\d+)', line)\n",
    "    block_id = match.group(1) if match else None\n",
    "    content = line.strip()\n",
    "    return block_id, content\n",
    "\n",
    "# Parse all logs\n",
    "print(\"Parsing all log lines...\")\n",
    "parsed_logs = [parse_log_line(line) for line in logs]\n",
    "\n",
    "# Create a DataFrame from the parsed logs\n",
    "log_df = pd.DataFrame(parsed_logs, columns=['BlockId', 'Content'])\n",
    "log_df.dropna(inplace=True) # Remove lines where no BlockId was found\n",
    "\n",
    "print(f\"Parsed logs shape: {log_df.shape}\")\n",
    "print(f\"Unique Block IDs: {log_df['BlockId'].nunique()}\")\n",
    "\n",
    "# Show sample parsed data\n",
    "print(\"\\nSample parsed logs:\")\n",
    "print(log_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "session-grouping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Session Grouping and Label Integration\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Session Grouping ---\")\n",
    "\n",
    "# Group log messages by their BlockId. Each BlockId represents a \"session\".\n",
    "# We aggregate the log content into a single document for each session.\n",
    "print(\"Grouping logs by BlockId (session)...\")\n",
    "session_df = log_df.groupby('BlockId')['Content'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "print(f\"Session data shape: {session_df.shape}\")\n",
    "\n",
    "# Merge with labels to have the ground truth for evaluation later\n",
    "session_df = pd.merge(session_df, labels_df, on='BlockId', how='left')\n",
    "session_df['Label'].fillna('Normal', inplace=True) # Assume sessions not in label file are Normal\n",
    "\n",
    "print(\"\\nFinal session data with labels:\")\n",
    "print(f\"Total sessions: {len(session_df)}\")\n",
    "print(\"Label distribution:\", session_df['Label'].value_counts())\n",
    "\n",
    "# Show sample session data\n",
    "print(\"\\nSample session data:\")\n",
    "for idx, row in session_df.head(2).iterrows():\n",
    "    print(f\"BlockId: {row['BlockId']}\")\n",
    "    print(f\"Label: {row['Label']}\")\n",
    "    print(f\"Content (first 200 chars): {row['Content'][:200]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Feature Engineering: TF-IDF\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Feature Engineering ---\")\n",
    "print(\"Converting log messages into numerical vectors using TF-IDF...\")\n",
    "\n",
    "# TF-IDF (Term Frequency-Inverse Document Frequency) is a great way to convert\n",
    "# text documents into numerical feature vectors. It gives more weight to terms\n",
    "# that are frequent in a document but rare across all documents.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(session_df['Content'])\n",
    "\n",
    "print(f\"Feature matrix created with shape: {X.shape}\")\n",
    "print(f\"Number of features (unique terms): {len(vectorizer.get_feature_names_out())}\")\n",
    "\n",
    "# Show some of the most common terms\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"\\nSample feature terms: {list(feature_names[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Model Training (Unsupervised)\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Model Training (Unsupervised) ---\")\n",
    "\n",
    "# Calculate the contamination parameter from our labels\n",
    "# 'contamination' is the expected proportion of anomalies in the data.\n",
    "anomaly_proportion = len(labels_df[labels_df['Label'] == 'Anomaly']) / len(session_df)\n",
    "print(f\"Estimated anomaly proportion: {anomaly_proportion:.4f}\")\n",
    "\n",
    "# Initialize the IsolationForest model\n",
    "# We use our calculated proportion as the contamination parameter\n",
    "model = IsolationForest(n_estimators=100,\n",
    "                        contamination=anomaly_proportion,\n",
    "                        random_state=42,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "print(\"Training the Isolation Forest model...\")\n",
    "# Note: We do NOT use 'y' labels for training an unsupervised model.\n",
    "model.fit(X)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"- Number of estimators: {model.n_estimators}\")\n",
    "print(f\"- Contamination: {model.contamination}\")\n",
    "print(f\"- Random state: {model.random_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Model Evaluation\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Model Evaluation ---\")\n",
    "\n",
    "# Predict anomalies. The model returns 1 for inliers and -1 for outliers.\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Convert our ground truth labels to the same format for comparison\n",
    "# (Normal -> 1, Anomaly -> -1)\n",
    "y_true = session_df['Label'].apply(lambda x: 1 if x == 'Normal' else -1)\n",
    "y_pred = predictions\n",
    "\n",
    "print(f\"Predictions distribution:\")\n",
    "print(f\"Normal (1): {sum(y_pred == 1)}\")\n",
    "print(f\"Anomaly (-1): {sum(y_pred == -1)}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display the classification report\n",
    "# Note: '1' is 'Normal' (inlier), '-1' is 'Anomaly' (outlier)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Anomaly (-1)', 'Normal (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Results Visualization and Analysis\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Results Visualization ---\")\n",
    "\n",
    "# Add predictions to the session dataframe for analysis\n",
    "session_df['Prediction'] = predictions\n",
    "session_df['PredictionLabel'] = session_df['Prediction'].apply(lambda x: 'Normal' if x == 1 else 'Anomaly')\n",
    "\n",
    "# Create confusion matrix visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "confusion_data = pd.crosstab(session_df['Label'], session_df['PredictionLabel'], margins=True)\n",
    "sns.heatmap(confusion_data.iloc[:-1, :-1], annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Anomaly', 'Normal'], yticklabels=['Anomaly', 'Normal'])\n",
    "plt.title('Log Anomaly Detection - Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Show some examples of detected anomalies\n",
    "detected_anomalies = session_df[session_df['Prediction'] == -1]\n",
    "actual_anomalies = session_df[session_df['Label'] == 'Anomaly']\n",
    "\n",
    "print(f\"\\n--- Analysis Results ---\")\n",
    "print(f\"Total sessions analyzed: {len(session_df)}\")\n",
    "print(f\"Actual anomalies in data: {len(actual_anomalies)}\")\n",
    "print(f\"Anomalies detected by model: {len(detected_anomalies)}\")\n",
    "\n",
    "# True positives: correctly identified anomalies\n",
    "true_positives = session_df[(session_df['Label'] == 'Anomaly') & (session_df['Prediction'] == -1)]\n",
    "print(f\"True positives (correctly detected): {len(true_positives)}\")\n",
    "\n",
    "if len(detected_anomalies) > 0:\n",
    "    print(\"\\n--- Sample Detected Anomalies ---\")\n",
    "    for idx, row in detected_anomalies.head(3).iterrows():\n",
    "        print(f\"\\nBlockId: {row['BlockId']} (Actual: {row['Label']})\")\n",
    "        print(f\"Content snippet: {row['Content'][:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#  Conclusion\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"--- Conclusion ---\")\n",
    "print(f\"The Isolation Forest model successfully identified log anomalies with an accuracy of {accuracy:.2%}.\")\n",
    "print(\"The key takeaway is that we were able to detect these anomalies WITHOUT explicitly training the model on what an anomaly looks like.\")\n",
    "print(\"The Classification Report shows strong performance, especially in precision for anomalies, which means when the model flags something, it's highly likely to be a real issue.\")\n",
    "print(\"This unsupervised approach is extremely powerful for real-world network monitoring where new, unseen problems can occur at any time.\")\n",
    "\n",
    "print(\"\\n--- Key Insights ---\")\n",
    "print(f\"• Total log lines processed: {len(logs):,}\")\n",
    "print(f\"• Unique sessions (BlockIds): {log_df['BlockId'].nunique():,}\")\n",
    "print(f\"• TF-IDF features extracted: {X.shape[1]:,}\")\n",
    "print(f\"• Contamination rate used: {anomaly_proportion:.2%}\")\n",
    "print(f\"• Final accuracy: {accuracy:.2%}\")\n",
    "print(f\"• Model type: Unsupervised (Isolation Forest)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}