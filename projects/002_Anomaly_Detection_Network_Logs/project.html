<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <title>Project 2: Basic Anomaly Detection in Network Logs - Anil Kumar SN</title>
      <script>
            (function() {
                const savedTheme = localStorage.getItem('theme');
                if (savedTheme === 'dark') {
                    document.documentElement.classList.add('dark-mode');
                }
            })();
        </script>
      <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;600;700;800&display=swap" rel="stylesheet">
      <link rel="stylesheet" href="../../css/styles.css?v=2">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
   </head>
   <body>
      <div class="main-container">
         <aside class="sidebar">
            <nav class="navbar">
               <a href="../../index.html">Home</a>
                <a href="../../html/about.html">About Me</a>
                <a href="../../html/llm_lingo.html">LLM Lingo</a>
               <a href="../../html/ml_youtube_courses.html">ML YouTube Courses</a>
               <a href="../../html/python_notebooks.html">Python Notebooks</a>
               <a href="../../html/AIML_Research.html">AI/ML Timeline</a>
               <a href="../../html/blogs.html">Blogs</a>
               <a href="../../html/Projects.html">Projects</a>
                <a href="../../html/llm_survey_papers.html">LLM Survey Papers</a>
                <a href="../../html/ai_datacenter_networking.html">AI Datacenter Networking</a>
            </nav>
            <div class="theme-switcher">
                <span>Light</span>
                <input type="checkbox" id="theme-toggle" class="theme-toggle">
                <label for="theme-toggle" class="toggle-label"></label>
                <span>Dark</span>
            </div>
         </aside>
         
         <main class="main-content">
            <header class="header">
                <h1>Project 2: Basic Anomaly Detection in Network Logs</h1>
                <p>Unsupervised Learning & Outlier Detection</p>
            </header>
            
            <section class="content section">
                <div class="card">
                    <div class="project-navigation">
                        <a href="../../html/Projects.html" class="nav-link">‚Üê Back to All Projects</a>
                        <div class="project-files">
                            <a href="notebook.ipynb" class="nav-link" download>üìì Download Notebook</a>
                            <a href="requirements.txt" class="nav-link" download>üìã Requirements.txt</a>
                        </div>
                    </div>
                    
                    <article class="project-content">
                        <h2>1. Objective</h2>
                        <p>To identify anomalous sequences of events in system logs using unsupervised machine learning. This project demonstrates how to detect faults, misconfigurations, or security incidents without needing prior examples of every possible bad event, making it crucial for proactive network monitoring.</p>

                        <h2>2. Business Value</h2>
                        <p>By automatically detecting log anomalies, we can:</p>
                        <ul>
                            <li><strong>Proactive Issue Detection:</strong> Identify problems before they impact customers</li>
                            <li><strong>Security Monitoring:</strong> Detect unusual patterns that may indicate security breaches</li>
                            <li><strong>System Health Monitoring:</strong> Catch configuration errors and system faults early</li>
                            <li><strong>Operational Efficiency:</strong> Reduce manual log analysis and accelerate incident response</li>
                        </ul>
                        <p>This capability enhances overall network reliability and security posture.</p>

                        <h2>3. Core Libraries</h2>
                        <ul>
                            <li><code>pandas</code>: For data manipulation and log processing</li>
                            <li><code>numpy</code>: For numerical operations and data handling</li>
                            <li><code>scikit-learn</code>: For the IsolationForest algorithm and TF-IDF vectorization</li>
                            <li><code>matplotlib</code> & <code>seaborn</code>: For visualization of results</li>
                            <li><code>re</code>: For regular expression-based log parsing</li>
                            <li><code>kaggle</code>: For dataset acquisition</li>
                        </ul>

                        <h2>4. Dataset</h2>
                        <ul>
                            <li><strong>Primary Dataset:</strong> <strong>HDFS Log Anomaly Detection Dataset</strong> (<a href="https://www.kaggle.com/datasets/logpai/hdfs-log-anomaly-detection" target="_blank">Available on Kaggle</a>)</li>
                            <li><strong>Why it's suitable:</strong> The HDFS dataset tracks events related to data block operations in a large computing cluster, making it an excellent proxy for complex network system logs. It contains both normal operational logs and anomalous sequences, with ground truth labels for evaluation. The logs represent realistic system behavior patterns that are similar to what network engineers encounter in production environments.</li>
                        </ul>

                        <h2>5. Detailed Step-by-Step Guide</h2>

                        <h3>Step 1: Setup the Environment</h3>
                        <ol>
                            <li>Create project environment and install dependencies</li>
                        </ol>
                        <pre><code class="language-bash">mkdir log-anomaly-detection
cd log-anomaly-detection
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate</code></pre>
                        
                        <ol start="2">
                            <li>Install required libraries</li>
                        </ol>
                        <pre><code class="language-bash">pip install pandas numpy scikit-learn matplotlib seaborn kaggle jupyterlab</code></pre>
                        
                        <ol start="3">
                            <li>Configure Kaggle API for data download</li>
                        </ol>
                        <pre><code class="language-bash"># Place kaggle.json in ~/.kaggle/
mkdir ~/.kaggle
cp kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json</code></pre>

                        <h3>Step 2: Data Acquisition and Loading</h3>
                        <ol>
                            <li>Download the HDFS log dataset</li>
                        </ol>
                        <pre><code class="language-python">import kaggle
kaggle.api.dataset_download_files('logpai/hdfs-log-anomaly-detection', unzip=True)</code></pre>
                        
                        <ol start="2">
                            <li>Load and examine the log data</li>
                        </ol>
                        <pre><code class="language-python">import pandas as pd
import re

# Load the ground truth labels
labels_df = pd.read_csv('anomaly_label.csv')
print("Labels loaded:", labels_df.shape)

# Load raw log file
with open('HDFS.log', 'r') as f:
    logs = f.readlines()
print(f"Total log lines: {len(logs)}")</code></pre>

                        <h3>Step 3: Log Parsing and Preprocessing</h3>
                        <ol>
                            <li><strong>Parse log entries to extract block IDs and content</strong></li>
                        </ol>
                        <pre><code class="language-python">def parse_log_line(line):
    # Extract block ID using regex
    match = re.search(r'(blk_[-]?\d+)', line)
    block_id = match.group(1) if match else None
    content = line.strip()
    return block_id, content

# Parse all logs
parsed_logs = [parse_log_line(line) for line in logs]
log_df = pd.DataFrame(parsed_logs, columns=['BlockId', 'Content'])
log_df.dropna(inplace=True)

print(f"Parsed logs: {log_df.shape}")</code></pre>
                        
                        <ol start="2">
                            <li><strong>Group logs by session (BlockId)</strong></li>
                        </ol>
                        <pre><code class="language-python"># Each BlockId represents a session - aggregate log content
print("Grouping logs by BlockId (session)...")
session_df = log_df.groupby('BlockId')['Content'].apply(
    lambda x: ' '.join(x)
).reset_index()

# Merge with ground truth labels
session_df = pd.merge(session_df, labels_df, on='BlockId', how='left')
session_df['Label'].fillna('Normal', inplace=True)

print(f"Session data shape: {session_df.shape}")
print("Label distribution:", session_df['Label'].value_counts())</code></pre>

                        <h3>Step 4: Feature Engineering with TF-IDF</h3>
                        <ol>
                            <li><strong>Convert log text to numerical vectors</strong></li>
                        </ol>
                        <pre><code class="language-python">from sklearn.feature_extraction.text import TfidfVectorizer

print("Converting log messages to TF-IDF vectors...")
# TF-IDF gives more weight to terms frequent in a document but rare across all documents
vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)
X = vectorizer.fit_transform(session_df['Content'])

print(f"Feature matrix shape: {X.shape}")</code></pre>

                        <h3>Step 5: Unsupervised Anomaly Detection</h3>
                        <ol>
                            <li><strong>Train Isolation Forest model</strong></li>
                        </ol>
                        <pre><code class="language-python">from sklearn.ensemble import IsolationForest

# Calculate expected anomaly proportion from labels
anomaly_proportion = len(labels_df[labels_df['Label'] == 'Anomaly']) / len(session_df)
print(f"Estimated anomaly proportion: {anomaly_proportion:.4f}")

# Initialize and train the model
model = IsolationForest(
    n_estimators=100,
    contamination=anomaly_proportion,
    random_state=42,
    n_jobs=-1
)

print("Training Isolation Forest model...")
model.fit(X)  # Unsupervised - no labels used in training
print("Training complete.")</code></pre>

                        <h3>Step 6: Model Evaluation</h3>
                        <ol>
                            <li><strong>Generate predictions and evaluate performance</strong></li>
                        </ol>
                        <pre><code class="language-python">from sklearn.metrics import classification_report, accuracy_score

# Predict anomalies (1 for normal, -1 for anomaly)
predictions = model.predict(X)

# Convert ground truth to same format
y_true = session_df['Label'].apply(lambda x: 1 if x == 'Normal' else -1)
y_pred = predictions

# Calculate metrics
accuracy = accuracy_score(y_true, y_pred)
print(f"Model Accuracy: {accuracy:.4f}")

print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=['Anomaly (-1)', 'Normal (1)']))</code></pre>

                        <h3>Step 7: Results Analysis and Visualization</h3>
                        <ol>
                            <li><strong>Analyze detected anomalies</strong></li>
                        </ol>
                        <pre><code class="language-python">import matplotlib.pyplot as plt
import seaborn as sns

# Add predictions to dataframe for analysis
session_df['Prediction'] = predictions

# Show examples of detected anomalies
detected_anomalies = session_df[session_df['Prediction'] == -1]
print(f"Detected {len(detected_anomalies)} anomalies")

# Visualization of results
plt.figure(figsize=(10, 6))
confusion_data = pd.crosstab(session_df['Label'], session_df['Prediction'])
sns.heatmap(confusion_data, annot=True, fmt='d', cmap='Blues')
plt.title('Log Anomaly Detection Results')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()</code></pre>

                        <h2>6. Success Criteria</h2>
                        <ul>
                            <li>Successfully parse and process log files into structured format</li>
                            <li>TF-IDF vectorization creates meaningful numerical features from log text</li>
                            <li>Isolation Forest model trains without errors and generates predictions</li>
                            <li>Model achieves reasonable precision/recall balance for anomaly detection</li>
                            <li>Clear visualization of results showing model performance</li>
                            <li>Ability to identify and analyze specific anomalous log sequences</li>
                        </ul>

                        <h2>7. Next Steps & Extensions</h2>
                        <ul>
                            <li><strong>Advanced Text Processing:</strong> Implement log templating to extract structured patterns</li>
                            <li><strong>Sequential Analysis:</strong> Use LSTM or other sequence models for temporal patterns</li>
                            <li><strong>Real-time Processing:</strong> Implement streaming anomaly detection for live logs</li>
                            <li><strong>Multi-source Integration:</strong> Combine logs from multiple system components</li>
                            <li><strong>Alert System:</strong> Build automated alerting based on anomaly scores</li>
                            <li><strong>Parameter Tuning:</strong> Optimize contamination parameter and TF-IDF settings</li>
                        </ul>
                    </article>
                </div>
            </section>
         </main>
      </div>
      
      <footer>
         <p>¬© 2025 Anil Kumar SN. All rights reserved.</p>
         <p><a href="https://www.linkedin.com/in/anil-sn/" target="_blank">LinkedIn</a> &nbsp;&middot;&nbsp; <a href="https://x.com/Anilsn_" target="_blank">Twitter</a> &nbsp;&middot;&nbsp; <a href="https://github.com/anil-sn" target="_blank">Github</a></p>
      </footer>
      
      <button id="backToTopBtn" title="Go to top">‚Üë</button>
      <script src="../../js/navigation.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
      <script src="../../js/main.js"></script>
   </body>
</html>