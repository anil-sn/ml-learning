<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Networking for AI Datacenters - Complete Learning Guide</title>
    <meta name="description" content="The complete guide to understanding AI datacenter networking - from fundamentals to advanced concepts. Learn InfiniBand, Ethernet, RoCE, and modern AI networking architectures.">
    <meta name="keywords" content="AI networking, datacenter networking, GPU clusters, InfiniBand, Ethernet, RoCE, NVLink, leaf-spine, AI/ML infrastructure, RDMA">
    <script>
        (function() {
            const savedTheme = localStorage.getItem('theme');
            if (savedTheme === 'dark') {
                document.documentElement.classList.add('dark-mode');
            }
        })();
    </script>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../css/styles.css?v=2">
</head>
<body>
    <div class="main-container">
        <aside class="sidebar">
            <nav class="navbar">
                <a href="../index.html">Home</a>
                <a href="about.html">About Me</a>
                <a href="llm_lingo.html">LLM Lingo</a>
                <a href="ml_youtube_courses.html">ML YouTube Courses</a>
                <a href="AIML_Research.html">AI/ML Timeline</a>
                <a href="blogs.html">Blogs</a>
                <a href="Projects.html">Projects</a>
                <a href="llm_survey_papers.html">LLM Survey Papers</a>
                <a href="ai_datacenter_networking.html" class="active">AI Datacenter Networking</a>
            </nav>
            <div class="theme-switcher">
                <span>Light</span>
                <input type="checkbox" id="theme-toggle" class="theme-toggle">
                <label for="theme-toggle" class="toggle-label"></label>
                <span>Dark</span>
            </div>
        </aside>
        
        <main class="main-content">
            <header class="header">
                <h1>Networking for AI Datacenters</h1>
                <p>The Complete Learning Guide to High-Performance AI Infrastructure</p>
            </header>
            
            <!-- Learning Path Navigation -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Learning Path</h2>
                    <div class="simple-list">
                        <div class="list-item">
                            <h3>1. Fundamentals</h3>
                            <p>Why AI needs special networking</p>
                        </div>
                        <div class="list-item">
                            <h3>2. Technologies</h3>
                            <p>InfiniBand, Ethernet, RoCE</p>
                        </div>
                        <div class="list-item">
                            <h3>3. Architectures</h3>
                            <p>Topologies and design patterns</p>
                        </div>
                        <div class="list-item">
                            <h3>4. Real World</h3>
                            <p>Case studies and implementations</p>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Technical Requirements Analysis -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">AI Network Requirements</h2>
                    
                    <h3>Key Communication Patterns</h3>
                    <p>AI training relies on specific communication patterns:</p>
                    
                    <div class="simple-content">
                        <h4>All-Reduce Operations</h4>
                        <p><strong>Purpose:</strong> Synchronize model gradients across all GPUs</p>
                        <p><strong>Network Impact:</strong> Requires full bisection bandwidth during gradient synchronization</p>
                        <p><strong>Example:</strong> GPT-3 175B parameters = 1.4TB per all-reduce operation</p>
                        
                        <h4>Traffic Characteristics</h4>
                        <ul>
                            <li><strong>99.9%</strong> East-West Traffic</li>
                            <li><strong>64KB - 1MB</strong> Message Size Range</li>
                            <li><strong>Elephant Flows</strong> - Large, sustained transfers</li>
                            <li><strong>Synchronized</strong> Communication Pattern</li>
                        </ul>
                        
                        <h4>Latency Requirements</h4>
                        <p><strong>Target:</strong> Less than 1.5μs end-to-end latency</p>
                        <ul>
                            <li>NIC Processing: 0.3-0.5μs</li>
                            <li>Switch Fabric: 0.1-0.2μs</li>
                            <li>Protocol Overhead: 0.1-0.3μs</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Core Technologies -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Core Technologies</h2>
                    
                    <h3>InfiniBand</h3>
                    <div class="simple-content">
                        <p><strong>What it is:</strong> High-performance interconnect designed for HPC and AI workloads</p>
                        
                        <h4>Key Features:</h4>
                        <ul>
                            <li><strong>Ultra-low latency:</strong> 600ns end-to-end</li>
                            <li><strong>High bandwidth:</strong> Up to 400 Gbps per link</li>
                            <li><strong>RDMA support:</strong> Direct memory access without CPU involvement</li>
                            <li><strong>Minimal CPU overhead:</strong> Less than 1% CPU usage</li>
                        </ul>
                        
                        <h4>Transport Types:</h4>
                        <ul>
                            <li><strong>RC (Reliable Connected):</strong> Best for RDMA operations</li>
                            <li><strong>UD (Unreliable Datagram):</strong> Used for management traffic</li>
                        </ul>
                    </div>

                    <h3>RoCE (RDMA over Converged Ethernet)</h3>
                    <div class="simple-content">
                        <p><strong>What it is:</strong> Brings InfiniBand performance to standard Ethernet infrastructure</p>
                        
                        <h4>Versions:</h4>
                        <ul>
                            <li><strong>RoCEv1:</strong> Layer 2 only, same broadcast domain</li>
                            <li><strong>RoCEv2:</strong> Layer 3 routable, production standard</li>
                        </ul>
                        
                        <h4>Key Technologies:</h4>
                        <ul>
                            <li><strong>DCQCN:</strong> Congestion control algorithm</li>
                            <li><strong>PFC:</strong> Priority Flow Control for lossless operation</li>
                            <li><strong>ECN:</strong> Explicit Congestion Notification</li>
                        </ul>
                    </div>

                    <h3>How RDMA Works</h3>
                    <div class="simple-content">
                        <ol>
                            <li><strong>Memory Registration:</strong> Applications register memory regions</li>
                            <li><strong>Direct Access:</strong> Remote applications can read/write directly</li>
                            <li><strong>Kernel Bypass:</strong> No CPU involvement in data path</li>
                            <li><strong>Zero Copy:</strong> Data moves directly between application memory</li>
                        </ol>
                        
                        <h4>Performance Benefits:</h4>
                        <ul>
                            <li><strong>95% CPU reduction</strong> - Frees CPU for computation</li>
                            <li><strong>10x bandwidth improvement</strong> - Higher throughput</li>
                            <li><strong>5x latency reduction</strong> - Faster communication</li>
                        </ul>
                    </div>

                    <h3>Emerging Technologies</h3>
                    <div class="simple-content">
                        <h4>Ultra Ethernet Consortium</h4>
                        <p>Industry initiative to enhance Ethernet for AI workloads:</p>
                        <ul>
                            <li>Enhanced congestion control algorithms</li>
                            <li>Improved multicast and telemetry support</li>
                            <li>Better job scheduling integration</li>
                        </ul>
                        <p><a href="https://ultraethernet.org/" target="_blank">Learn More →</a></p>
                        
                        <h4>NVIDIA SHARP</h4>
                        <p>In-network computing for AI collective operations:</p>
                        <ul>
                            <li>All-reduce operations in network switches</li>
                            <li>Reduces network traffic significantly</li>
                            <li>Up to 2x acceleration for large models</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Network Architectures -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Network Architectures</h2>
                    
                    <h3>Leaf-Spine (Clos Fabric)</h3>
                    <div class="simple-content">
                        <p><strong>What it is:</strong> The most common architecture for AI data centers</p>
                        
                        <h4>Key Characteristics:</h4>
                        <ul>
                            <li><strong>Non-blocking:</strong> Every server can communicate at full speed</li>
                            <li><strong>Scalable:</strong> Add more leaf switches to grow capacity</li>
                            <li><strong>Low oversubscription:</strong> 1:1 to 3:1 ratios typical</li>
                            <li><strong>ECMP load balancing:</strong> Multiple paths between endpoints</li>
                        </ul>
                        
                        <h4>Multi-Rail Design:</h4>
                        <ul>
                            <li><strong>Rail 0:</strong> Compute traffic (RoCE/InfiniBand)</li>
                            <li><strong>Rail 1:</strong> Storage traffic (NVMe-oF)</li>
                            <li><strong>Rail 2:</strong> Management traffic</li>
                        </ul>
                    </div>

                    <h3>DragonFly+ Topology</h3>
                    <div class="simple-content">
                        <p><strong>What it is:</strong> Advanced topology for extremely large-scale AI clusters</p>
                        
                        <h4>Key Features:</h4>
                        <ul>
                            <li><strong>Hierarchical design:</strong> Groups of routers connected globally</li>
                            <li><strong>Adaptive routing:</strong> Routes adapt based on congestion</li>
                            <li><strong>High scalability:</strong> Supports 100,000+ endpoints</li>
                            <li><strong>Fault tolerance:</strong> Multiple paths between any two points</li>
                        </ul>
                    </div>
                    
                    <h3>Scaling Examples</h3>
                    <div class="simple-content">
                        <h4>Pod-Based Architecture (Meta)</h4>
                        <ul>
                            <li><strong>Scale:</strong> 2,000-4,000 GPUs per pod</li>
                            <li><strong>Within pod:</strong> 400G InfiniBand</li>
                            <li><strong>Between pods:</strong> Ethernet spine</li>
                        </ul>
                        
                        <h4>3D Torus (Google TPU)</h4>
                        <ul>
                            <li><strong>Scale:</strong> 100,000+ accelerators</li>
                            <li><strong>Topology:</strong> Custom 3D mesh</li>
                            <li><strong>Bandwidth:</strong> 2.4Tbps per chip</li>
                        </ul>
                    </div>

                    <h3>AI Traffic Patterns</h3>
                    <div class="simple-content">
                        <h4>All-Reduce (Model Synchronization)</h4>
                        <ul>
                            <li><strong>Pattern:</strong> Every GPU communicates with every other GPU</li>
                            <li><strong>Requirement:</strong> Full bisection bandwidth</li>
                            <li><strong>Algorithms:</strong> Ring, tree, or hierarchical approaches</li>
                        </ul>
                        
                        <h4>All-Gather (Data Distribution)</h4>
                        <ul>
                            <li><strong>Pattern:</strong> Collect data from all nodes</li>
                            <li><strong>Use case:</strong> Embedding updates, parameter sharing</li>
                            <li><strong>Bottleneck:</strong> Memory bandwidth</li>
                        </ul>
                        
                        <h4>Point-to-Point (Data Loading)</h4>
                        <ul>
                            <li><strong>Pattern:</strong> Storage to compute (north-south)</li>
                            <li><strong>Characteristics:</strong> Large sequential transfers</li>
                            <li><strong>Solution:</strong> Separate storage network or QoS</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Real-World Implementations -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Real-World Case Studies</h2>
                    
                    <div class="simple-content">
                        <h3>OpenAI GPT Infrastructure</h3>
                        <ul>
                            <li><strong>Scale:</strong> 25,000+ NVIDIA V100/A100 GPUs</li>
                            <li><strong>Network:</strong> InfiniBand HDR (200Gbps)</li>
                            <li><strong>Platform:</strong> Microsoft Azure</li>
                            <li><strong>Innovation:</strong> Custom optimization for transformer models</li>
                        </ul>
                        <p><a href="https://arxiv.org/abs/2005.14165" target="_blank">GPT-3 Paper</a> | <a href="https://azure.microsoft.com/en-us/blog/how-microsoft-azure-is-powering-openai/" target="_blank">Azure Blog</a></p>
                        
                        <h3>Meta AI Research SuperCluster (RSC)</h3>
                        <ul>
                            <li><strong>Scale:</strong> 16,000 NVIDIA A100 GPUs</li>
                            <li><strong>Network:</strong> NVIDIA Quantum InfiniBand (400Gbps)</li>
                            <li><strong>Storage:</strong> 175PB Pure Storage FlashArray</li>
                            <li><strong>Design:</strong> Non-blocking fat-tree, 1:1 oversubscription</li>
                        </ul>
                        <p><a href="https://ai.facebook.com/blog/announcing-ai-research-supercluster/" target="_blank">Meta Announcement</a> | <a href="https://engineering.fb.com/2022/01/24/data-center-engineering/ai-rsc/" target="_blank">Technical Deep Dive</a></p>
                        
                        <h3>NVIDIA DGX SuperPOD</h3>
                        <ul>
                            <li><strong>Scale:</strong> 160 H100 GPUs per pod</li>
                            <li><strong>Network:</strong> Quantum-2 InfiniBand (400Gbps)</li>
                            <li><strong>Performance:</strong> 8 exaflops FP8, sub-μs latency</li>
                            <li><strong>Efficiency:</strong> >90% scaling up to 32,000 GPUs</li>
                        </ul>
                        <p><a href="https://docs.nvidia.com/dgx/dgx-superpod-reference-architecture/index.html" target="_blank">Architecture Guide</a> | <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/" target="_blank">Technical Overview</a></p>
                        
                        <h3>Google TPU Pod</h3>
                        <ul>
                            <li><strong>Scale:</strong> 100,000+ accelerators</li>
                            <li><strong>Topology:</strong> Custom 3D torus</li>
                            <li><strong>Bandwidth:</strong> 2.4 Tbps per chip</li>
                            <li><strong>Innovation:</strong> Hardware all-reduce implementation</li>
                        </ul>
                        <p><a href="https://arxiv.org/abs/1704.04760" target="_blank">TPU Paper</a> | <a href="https://cloud.google.com/tpu/docs/system-architecture-tpu-vm" target="_blank">Architecture Docs</a></p>
                    </div>
                </div>
            </section>

            <!-- Practical Implementation Guide -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Implementation Guide</h2>
                    
                    <div class="simple-content">
                        <h3>Planning Your AI Network</h3>
                        
                        <h4>Key Questions:</h4>
                        <ul>
                            <li>What's your target model size?</li>
                            <li>Training vs. inference workload?</li>
                            <li>Budget constraints?</li>
                            <li>Growth plans?</li>
                        </ul>
                        
                        <h4>Technology Selection:</h4>
                        
                        <p><strong>Choose InfiniBand if:</strong></p>
                        <ul>
                            <li>Ultra-low latency required (&lt;1μs)</li>
                            <li>Budget allows premium cost</li>
                            <li>Pure HPC/AI workloads</li>
                            <li>NVIDIA GPU ecosystem</li>
                        </ul>
                        
                        <p><strong>Choose RoCE if:</strong></p>
                        <ul>
                            <li>Cost optimization priority</li>
                            <li>Multi-vendor preference</li>
                            <li>Existing Ethernet expertise</li>
                            <li>Mixed datacenter workloads</li>
                        </ul>
                        
                        <h4>Design Principles:</h4>
                        <ul>
                            <li><strong>Low oversubscription:</strong> 1:1 or 2:1 ratios (vs. 20:1 enterprise)</li>
                            <li><strong>Fault tolerance:</strong> Single switch failure shouldn't stop jobs</li>
                            <li><strong>Cable management:</strong> Plan early - AI clusters are cable-dense</li>
                        </ul>
                        
                        <h4>Configuration Checklist:</h4>
                        
                        <p><strong>RoCE Setup:</strong></p>
                        <ul>
                            <li>Enable PFC on appropriate traffic classes</li>
                            <li>Configure DCQCN congestion control</li>
                            <li>Set buffer sizes (20MB+ recommended)</li>
                            <li>Enable ECN marking</li>
                        </ul>
                        
                        <p><strong>System Optimization:</strong></p>
                        <ul>
                            <li>NUMA topology awareness</li>
                            <li>CPU affinity for RDMA interrupts</li>
                            <li>Jumbo frames (9000+ bytes MTU)</li>
                            <li>Network buffer tuning</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Monitoring and Troubleshooting -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Monitoring & Troubleshooting</h2>
                    
                    <div class="simple-content">
                        <h3>Key Monitoring Tools</h3>
                        
                        <h4>InfiniBand:</h4>
                        <ul>
                            <li><code>ibstat</code> - Check adapter status</li>
                            <li><code>perfquery -a</code> - Performance counters</li>
                            <li><code>ibnetdiscover</code> - Fabric discovery</li>
                        </ul>
                        
                        <h4>RoCE/Ethernet:</h4>
                        <ul>
                            <li><code>ethtool -S eth0</code> - Interface statistics</li>
                            <li><code>dcbtool gc eth0 pfc</code> - PFC status</li>
                            <li>Monitor PFC pause frames and ECN marks</li>
                        </ul>
                        
                        <h4>NCCL Performance:</h4>
                        <ul>
                            <li><code>nccl-tests/build/all_reduce_perf</code> - Benchmark collectives</li>
                            <li>Set <code>NCCL_DEBUG=INFO</code> for detailed logging</li>
                            <li>Monitor algorithm bandwidth (algbw) and bus bandwidth (busbw)</li>
                        </ul>
                        
                        <h3>Common Issues & Solutions</h3>
                        
                        <h4>RDMA Transport Timeouts:</h4>
                        <ul>
                            <li><strong>Symptoms:</strong> Connection failures, QP errors</li>
                            <li><strong>Check:</strong> Cable integrity, switch buffer config</li>
                            <li><strong>Fix:</strong> Increase timeout values, replace cables</li>
                        </ul>
                        
                        <h4>PFC Deadlocks:</h4>
                        <ul>
                            <li><strong>Symptoms:</strong> Sustained pause storms, traffic stoppage</li>
                            <li><strong>Check:</strong> PFC counters with <code>ethtool -S</code></li>
                            <li><strong>Fix:</strong> Enable PFC watchdog, tune buffer thresholds</li>
                        </ul>
                        
                        <h4>Poor All-Reduce Performance:</h4>
                        <ul>
                            <li><strong>Symptoms:</strong> Low bandwidth utilization</li>
                            <li><strong>Check:</strong> GPU-NIC affinity with <code>nvidia-smi topo -m</code></li>
                            <li><strong>Fix:</strong> Tune NCCL algorithms, check network balance</li>
                        </ul>
                        
                        <h4>Packet Corruption:</h4>
                        <ul>
                            <li><strong>Symptoms:</strong> CRC errors, symbol errors</li>
                            <li><strong>Check:</strong> Physical layer stats with <code>ibstat</code></li>
                            <li><strong>Fix:</strong> Replace cables, check FEC settings, update firmware</li>
                        </ul>
                        
                        <h3>Performance Targets</h3>
                        <ul>
                            <li><strong>Latency:</strong> InfiniBand &lt;1μs, RoCE &lt;2μs</li>
                            <li><strong>Bandwidth utilization:</strong> &gt;90% for AI workloads</li>
                            <li><strong>Packet loss:</strong> 0% (lossless with PFC)</li>
                            <li><strong>All-reduce efficiency:</strong> &gt;80% of theoretical</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Video Resources -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Expert Video Resources</h2>
                    <p>Learn from industry experts with these carefully curated video resources:</p>
                    
                    <div class="video-grid">
                        <div class="video-card" data-video-url="https://youtu.be/rVW6N-ECyq0?si=vYHc-JRF7Mb6Zw-9">
                            <div class="video-thumbnail">
                                <img src="https://img.youtube.com/vi/rVW6N-ECyq0/maxresdefault.jpg" alt="AI Data Center Networks">
                                <div class="video-play-overlay">
                                    <svg width="68" height="48" viewBox="0 0 68 48" xmlns="http://www.w3.org/2000/svg">
                                        <path d="M66.52,7.74c-0.78-2.93-2.49-5.41-5.42-6.19C55.79,.13,34,0,34,0S12.21,.13,6.9,1.55 C3.97,2.33,2.27,4.81,1.48,7.74C0.06,13.05,0,24,0,24s0.06,10.95,1.48,16.26c0.78,2.93,2.49,5.41,5.42,6.19 C12.21,47.87,34,48,34,48s21.79-0.13,27.1-1.55c2.93-0.78,4.64-3.26,5.42-6.19C67.94,34.95,68,24,68,24S67.94,13.05,66.52,7.74z" fill="#f00"></path>
                                        <path d="M45,24 27,14 27,34" fill="#fff"></path>
                                    </svg>
                                </div>
                                <div class="video-duration">28:45</div>
                            </div>
                            <div class="video-info">
                                <h3 class="video-title">AI Data Center Networks - Fundamentals</h3>
                                <p class="video-description">Comprehensive overview of networking challenges and solutions in AI data centers, perfect for beginners understanding the fundamental requirements.</p>
                                <div class="video-tags">
                                    <span class="video-tag">Fundamentals</span>
                                    <span class="video-tag">Overview</span>
                                </div>
                            </div>
                        </div>

                        <div class="video-card" data-video-url="https://youtu.be/Jf8EPSBZU7Y?si=ufDalwc55hFmTQlN">
                            <div class="video-thumbnail">
                                <img src="https://img.youtube.com/vi/Jf8EPSBZU7Y/maxresdefault.jpg" alt="Inside xAI Colossus Supercluster">
                                <div class="video-play-overlay">
                                    <svg width="68" height="48" viewBox="0 0 68 48" xmlns="http://www.w3.org/2000/svg">
                                        <path d="M66.52,7.74c-0.78-2.93-2.49-5.41-5.42-6.19C55.79,.13,34,0,34,0S12.21,.13,6.9,1.55 C3.97,2.33,2.27,4.81,1.48,7.74C0.06,13.05,0,24,0,24s0.06,10.95,1.48,16.26c0.78,2.93,2.49,5.41,5.42,6.19 C12.21,47.87,34,48,34,48s21.79-0.13,27.1-1.55c2.93-0.78,4.64-3.26,5.42-6.19C67.94,34.95,68,24,68,24S67.94,13.05,66.52,7.74z" fill="#f00"></path>
                                        <path d="M45,24 27,14 27,34" fill="#fff"></path>
                                    </svg>
                                </div>
                                <div class="video-duration">45:12</div>
                            </div>
                            <div class="video-info">
                                <h3 class="video-title">Inside xAI Colossus: World's Largest AI Supercluster</h3>
                                <p class="video-description">Exclusive look inside xAI's massive 100,000-GPU Colossus supercluster networking architecture, showcasing real-world implementation at unprecedented scale.</p>
                                <div class="video-tags">
                                    <span class="video-tag">Case Study</span>
                                    <span class="video-tag">xAI</span>
                                    <span class="video-tag">Scale</span>
                                </div>
                            </div>
                        </div>

                        <div class="video-card" data-video-url="https://youtu.be/6t041Lr5FCY?si=OnUBLGapuTD1_o6t">
                            <div class="video-thumbnail">
                                <img src="https://img.youtube.com/vi/6t041Lr5FCY/maxresdefault.jpg" alt="Everything About RDMA">
                                <div class="video-play-overlay">
                                    <svg width="68" height="48" viewBox="0 0 68 48" xmlns="http://www.w3.org/2000/svg">
                                        <path d="M66.52,7.74c-0.78-2.93-2.49-5.41-5.42-6.19C55.79,.13,34,0,34,0S12.21,.13,6.9,1.55 C3.97,2.33,2.27,4.81,1.48,7.74C0.06,13.05,0,24,0,24s0.06,10.95,1.48,16.26c0.78,2.93,2.49,5.41,5.42,6.19 C12.21,47.87,34,48,34,48s21.79-0.13,27.1-1.55c2.93-0.78,4.64-3.26,5.42-6.19C67.94,34.95,68,24,68,24S67.94,13.05,66.52,7.74z" fill="#f00"></path>
                                        <path d="M45,24 27,14 27,34" fill="#fff"></path>
                                    </svg>
                                </div>
                                <div class="video-duration">41:27</div>
                            </div>
                            <div class="video-info">
                                <h3 class="video-title">Everything You Wanted to Know About RDMA</h3>
                                <p class="video-description">Comprehensive deep-dive into Remote Direct Memory Access technology, essential for understanding modern AI networking performance.</p>
                                <div class="video-tags">
                                    <span class="video-tag">RDMA</span>
                                    <span class="video-tag">Deep Dive</span>
                                    <span class="video-tag">Technical</span>
                                </div>
                            </div>
                        </div>

                        <div class="video-card" data-video-url="https://www.youtube.com/watch?v=H564lUSK804">
                            <div class="video-thumbnail">
                                <img src="https://img.youtube.com/vi/H564lUSK804/maxresdefault.jpg" alt="Scaling RoCE Networks">
                                <div class="video-play-overlay">
                                    <svg width="68" height="48" viewBox="0 0 68 48" xmlns="http://www.w3.org/2000/svg">
                                        <path d="M66.52,7.74c-0.78-2.93-2.49-5.41-5.42-6.19C55.79,.13,34,0,34,0S12.21,.13,6.9,1.55 C3.97,2.33,2.27,4.81,1.48,7.74C0.06,13.05,0,24,0,24s0.06,10.95,1.48,16.26c0.78,2.93,2.49,5.41,5.42,6.19 C12.21,47.87,34,48,34,48s21.79-0.13,27.1-1.55c2.93-0.78,4.64-3.26,5.42-6.19C67.94,34.95,68,24,68,24S67.94,13.05,66.52,7.74z" fill="#f00"></path>
                                        <path d="M45,24 27,14 27,34" fill="#fff"></path>
                                    </svg>
                                </div>
                                <div class="video-duration">35:44</div>
                            </div>
                            <div class="video-info">
                                <h3 class="video-title">Scaling RoCE Networks for AI Training</h3>
                                <p class="video-description">Expert insights into scaling RoCE networks for AI training workloads, covering practical implementation challenges and solutions.</p>
                                <div class="video-tags">
                                    <span class="video-tag">RoCE</span>
                                    <span class="video-tag">Scaling</span>
                                    <span class="video-tag">Practical</span>
                                </div>
                            </div>
                        </div>

                        <div class="video-card" data-video-url="https://youtu.be/pdCP-35aUlM?si=BkhMGcAKDUjc3_md">
                            <div class="video-thumbnail">
                                <img src="https://img.youtube.com/vi/pdCP-35aUlM/maxresdefault.jpg" alt="NVIDIA RDMA Programming">
                                <div class="video-play-overlay">
                                    <svg width="68" height="48" viewBox="0 0 68 48" xmlns="http://www.w3.org/2000/svg">
                                        <path d="M66.52,7.74c-0.78-2.93-2.49-5.41-5.42-6.19C55.79,.13,34,0,34,0S12.21,.13,6.9,1.55 C3.97,2.33,2.27,4.81,1.48,7.74C0.06,13.05,0,24,0,24s0.06,10.95,1.48,16.26c0.78,2.93,2.49,5.41,5.42,6.19 C12.21,47.87,34,48,34,48s21.79-0.13,27.1-1.55c2.93-0.78,4.64-3.26,5.42-6.19C67.94,34.95,68,24,68,24S67.94,13.05,66.52,7.74z" fill="#f00"></path>
                                        <path d="M45,24 27,14 27,34" fill="#fff"></path>
                                    </svg>
                                </div>
                                <div class="video-duration">38:56</div>
                            </div>
                            <div class="video-info">
                                <h3 class="video-title">RDMA Programming: NVIDIA's Guide</h3>
                                <p class="video-description">NVIDIA's comprehensive guide to high-performance RDMA programming, covering practical implementation techniques for AI applications.</p>
                                <div class="video-tags">
                                    <span class="video-tag">Programming</span>
                                    <span class="video-tag">NVIDIA</span>
                                    <span class="video-tag">Tutorial</span>
                                </div>
                            </div>
                        </div>

                        <div class="video-card" data-video-url="https://youtu.be/oDBMv_5rbQg?si=W_TIVag9jZWXy89i">
                            <div class="video-thumbnail">
                                <img src="https://img.youtube.com/vi/oDBMv_5rbQg/maxresdefault.jpg" alt="RDMA over Ethernet for AI Training">
                                <div class="video-play-overlay">
                                    <svg width="68" height="48" viewBox="0 0 68 48" xmlns="http://www.w3.org/2000/svg">
                                        <path d="M66.52,7.74c-0.78-2.93-2.49-5.41-5.42-6.19C55.79,.13,34,0,34,0S12.21,.13,6.9,1.55 C3.97,2.33,2.27,4.81,1.48,7.74C0.06,13.05,0,24,0,24s0.06,10.95,1.48,16.26c0.78,2.93,2.49,5.41,5.42,6.19 C12.21,47.87,34,48,34,48s21.79-0.13,27.1-1.55c2.93-0.78,4.64-3.26,5.42-6.19C67.94,34.95,68,24,68,24S67.94,13.05,66.52,7.74z" fill="#f00"></path>
                                        <path d="M45,24 27,14 27,34" fill="#fff"></path>
                                    </svg>
                                </div>
                                <div class="video-duration">47:33</div>
                            </div>
                            <div class="video-info">
                                <h3 class="video-title">SIGCOMM'24: RDMA over Ethernet for AI Training</h3>
                                <p class="video-description">Academic presentation from SIGCOMM covering the latest research in RDMA over Ethernet implementations for distributed AI training systems.</p>
                                <div class="video-tags">
                                    <span class="video-tag">Research</span>
                                    <span class="video-tag">SIGCOMM</span>
                                    <span class="video-tag">Academic</span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Additional Resources -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Additional Resources</h2>
                    
                    <div class="simple-content">
                        <h3>Essential Documentation</h3>
                        <ul>
                            <li><a href="https://docs.nvidia.com/networking/" target="_blank">NVIDIA Networking Documentation</a> - InfiniBand, Ethernet, and software stack</li>
                            <li><a href="https://ultraethernet.org/resources/" target="_blank">Ultra Ethernet Consortium</a> - Industry specifications for AI networking</li>
                            <li><a href="https://www.opencompute.org/projects/networking" target="_blank">OpenCompute Project</a> - Open source hardware designs for datacenter networking</li>
                        </ul>
                        
                        <h3>Tools and Software</h3>
                        <ul>
                            <li><a href="https://github.com/NVIDIA/nccl" target="_blank">NCCL</a> - GPU-aware collective communications library</li>
                            <li><a href="https://www.open-mpi.org/" target="_blank">OpenMPI</a> - High-performance message passing with RDMA support</li>
                            <li><a href="https://github.com/linux-rdma/perftest" target="_blank">RDMA Performance Testing Suite</a> - Benchmarking tools</li>
                            <li><a href="https://www.nvidia.com/en-us/networking/ethernet-switching/netq/" target="_blank">NVIDIA NetQ</a> - Network operations and monitoring</li>
                        </ul>
                        
                        <h3>Training and Courses</h3>
                        <ul>
                            <li><a href="https://www.nvidia.com/en-us/training/" target="_blank">NVIDIA Deep Learning Institute</a> - Professional AI infrastructure training</li>
                            <li><a href="https://www.broadcom.com/support/education" target="_blank">Broadcom University</a> - Enterprise datacenter networking training</li>
                            <li><a href="https://training.linuxfoundation.org/" target="_blank">Linux Foundation Training</a> - Modern networking technologies</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Quick Reference -->
            <section class="topic-section">
                <div class="card">
                    <h2 class="section-title">Quick Reference</h2>
                    
                    <div class="simple-content">
                        <h3>Essential Commands</h3>
                        <ul>
                            <li><code>ibstat</code> - Check InfiniBand adapter status</li>
                            <li><code>ibv_devinfo</code> - Display RDMA device information</li>
                            <li><code>ib_write_bw</code> - Measure RDMA write bandwidth</li>
                            <li><code>ethtool -S eth0</code> - Ethernet interface statistics</li>
                            <li><code>mlnx_qos -i eth0</code> - Check PFC and QoS status</li>
                        </ul>
                        
                        <h3>Performance Targets</h3>
                        <ul>
                            <li><strong>Latency:</strong> InfiniBand &lt;1μs, RoCE &lt;2μs</li>
                            <li><strong>Bandwidth Utilization:</strong> &gt;90% for AI workloads</li>
                            <li><strong>Packet Loss:</strong> 0% (lossless with PFC)</li>
                            <li><strong>All-Reduce Efficiency:</strong> &gt;80% of theoretical</li>
                        </ul>
                    </div>
                </div>
            </section>
        </main>
    </div>
    
    <footer>
        <p>© 2025 Anil Kumar SN. All rights reserved.</p>
        <p><a href="https://www.linkedin.com/in/anil-sn/" target="_blank">LinkedIn</a> &nbsp;&middot;&nbsp; <a href="https://x.com/Anilsn_" target="_blank">Twitter</a> &nbsp;&middot;&nbsp; <a href="https://github.com/anil-sn" target="_blank">Github</a></p>
    </footer>
    
    <button id="backToTopBtn" title="Go to top">↑</button>
    <script src="../js/main.js"></script>
</body>
</html>